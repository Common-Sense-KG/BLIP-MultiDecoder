Creating captioning dataset
Creating model
load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_caption_capfilt_large.pth
Finish Creating model- pretrain
Start training
Train Caption Epoch: [0]
Averaged stats: lr: 0.0000  loss: 11.6519
update min loss in epoch 0
min loss is 11.652
Train Caption Epoch: [1]
Averaged stats: lr: 0.0000  loss: 9.4699
update min loss in epoch 1
min loss is 9.470
Train Caption Epoch: [2]
Averaged stats: lr: 0.0000  loss: 9.4923
Train Caption Epoch: [3]
Averaged stats: lr: 0.0000  loss: 9.4151
update min loss in epoch 3
min loss is 9.415
Train Caption Epoch: [4]
